{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "from dataset import Dataset\n",
    "from trainer import MatchingModelTrainer\n",
    "from preprocessor import Preprocessor\n",
    "from utils.dirs import create_dirs\n",
    "from utils.logger import SummaryWriter\n",
    "from utils.config import load_config, save_config\n",
    "from models.base import get_model\n",
    "from utils.utils import JamoProcessor\n",
    "\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.mode = \"train\"\n",
    "        self.name = \"debug2000\"\n",
    "        self.config = \"\"\n",
    "        self.train_dir = \"/media/scatter/scatterdisk/reply_matching_model/sol.tokenized.sent_piece_100K/\"\n",
    "        self.val_dir = \"/media/scatter/scatterdisk/reply_matching_model/sol.tokenized.sent_piece_100K/sol.validation.txt\"\n",
    "        self.pretrained_embed_dir = \"/media/scatter/scatterdisk/pretrained_embedding/fasttext.sent_piece_100K.256D\"\n",
    "        self.checkpoint_dir = \"/home/angrypark/\"\n",
    "        self.model = \"DualEncoderTransformerDense2\"\n",
    "        self.sent_piece_model = \"/media/scatter/scatterdisk/tokenizer/sent_piece.50K.model\"\n",
    "        self.soynlp_scores = \"/media/scatter/scatterdisk/tokenizer/soynlp_scores.sol.100M.txt\"\n",
    "        self.normalizer = \"DummyNormalizer\"\n",
    "        self.tokenizer = \"DummyTokenizer\"\n",
    "        self.vocab_size = 90000\n",
    "        self.vocab_list = \"/media/scatter/scatterdisk/pretrained_embedding/vocab_list.sent_piece_100K.txt\"\n",
    "        \n",
    "        self.embed_dim = 256\n",
    "        self.learning_rate = 1e-1\n",
    "        self.min_length = 1\n",
    "        self.max_length = 20\n",
    "        self.embed_dropout_keep_prob = 0.9\n",
    "        self.lstm_dropout_keep_prob = 0.9\n",
    "        \n",
    "        self.lstm_dim = 512\n",
    "        self.negative_sampling = \"random\"\n",
    "        self.num_negative_samples = 4\n",
    "        self.add_echo = False\n",
    "        \n",
    "        self.batch_size = 512\n",
    "        self.num_epochs = 300\n",
    "        self.evaluate_every = 100000\n",
    "        self.save_every = 1000000\n",
    "        \n",
    "        self.max_to_keep = 1\n",
    "        self.shuffle = True\n",
    "        \n",
    "        self.filter_sizes=\"2,3\"\n",
    "        self.num_filters=64\n",
    "        self.num_hidden=128\n",
    "        self.hidden_dropout_keep_prob=0.9\n",
    "        self.dense_dropout_keep_prob=0.9\n",
    "        \n",
    "        self.weak_supervision=False\n",
    "        self.hinge_loss = 0.3\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_dirs(config)\n",
    "device_config = tf.ConfigProto()\n",
    "device_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=device_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(preprocessor, \n",
    "               config.train_dir, \n",
    "               config.val_dir, \n",
    "               config.min_length, \n",
    "               config.max_length, \n",
    "               config.num_negative_samples,\n",
    "               config.batch_size, \n",
    "               config.shuffle, \n",
    "               config.num_epochs, \n",
    "               debug=False)\n",
    "summary_writer = SummaryWriter(sess, config)\n",
    "trainer = MatchingModelTrainer(sess, preprocessor, data, config, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_size = 10000\n",
    "data.val_size = 10000\n",
    "trainer.num_steps_per_epoch = (10000 - 1) // config.batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[21:56:46][INFO] Building train graph... \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "Pre-trained embedding loaded. Number of OOV : 5272 / 90000\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      ":::MLPv0.5.0 transformer 1541163411.067282438 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "WARNING:tensorflow:Without a Problem, T2TModel.bottom is a passthrough.\n",
      "INFO:tensorflow:Building model body\n",
      ":::MLPv0.5.0 transformer 1541163411.177893639 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1541163411.187114000 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_attention_num_heads: 4\n",
      ":::MLPv0.5.0 transformer 1541163411.195665598 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_attention_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163411.530338287 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
      ":::MLPv0.5.0 transformer 1541163411.539752960 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1541163411.551838398 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163411.910696983 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
      ":::MLPv0.5.0 transformer 1541163411.921986103 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1541163411.931446552 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163412.134832859 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_norm: {\"hidden_size\": 256}\n",
      "WARNING:tensorflow:Without a Problem, T2TModel.top is a passthrough.\n",
      "WARNING:tensorflow:The default implementation of loss requires that the model be used with a Problem. If using a Problem, augment the hparams object with trainer_lib.add_problem_hparams. If not, override loss.\n",
      ":::MLPv0.5.0 transformer 1541163412.172503233 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/t2t_model.py:213) model_hp_initializer_gain: 1.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "WARNING:tensorflow:Without a Problem, T2TModel.bottom is a passthrough.\n",
      "INFO:tensorflow:Building model body\n",
      ":::MLPv0.5.0 transformer 1541163412.251137018 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1541163412.259961605 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_attention_num_heads: 4\n",
      ":::MLPv0.5.0 transformer 1541163412.268716097 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_attention_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163412.471784592 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
      ":::MLPv0.5.0 transformer 1541163412.483869076 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1541163412.492453337 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163412.857293606 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_filter: {\"filter_size\": 1024, \"use_bias\": \"True\", \"activation\": \"relu\"}\n",
      ":::MLPv0.5.0 transformer 1541163412.866543293 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_ffn_dense: {\"hidden_size\": 256, \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1541163412.876241207 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/layers/transformer_layers.py:182) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1541163412.968364477 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/models/transformer.py:1106) model_hp_norm: {\"hidden_size\": 256}\n",
      "WARNING:tensorflow:Without a Problem, T2TModel.top is a passthrough.\n",
      "WARNING:tensorflow:The default implementation of loss requires that the model be used with a Problem. If using a Problem, augment the hparams object with trainer_lib.add_problem_hparams. If not, override loss.\n",
      "INFO:tensorflow:Trainable Variables Total size: 24758274\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      ":::MLPv0.5.0 transformer 1541163413.116550207 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:45) opt_name: \"Adam\"\n",
      ":::MLPv0.5.0 transformer 1541163413.126629829 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_beta1: 0.9\n",
      ":::MLPv0.5.0 transformer 1541163413.138741970 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_beta2: 0.997\n",
      ":::MLPv0.5.0 transformer 1541163413.150315762 (/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensor2tensor/utils/optimize.py:45) opt_hp_Adam_epsilon: 1e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/envs/angryenv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\u001b[32m[21:56:59][INFO] Loading checkpoint from /home/angrypark/debug2000/ \u001b[0m\n",
      "\u001b[31m[21:56:59][ERROR] No checkpoint found in /home/angrypark/debug2000/ \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, sess = trainer.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {model.lstm_dropout_keep_prob: 1,\n",
    "             model.num_negative_samples: config.num_negative_samples,\n",
    "             model.embed_dropout_keep_prob: 1,\n",
    "             model.dense_dropout_keep_prob: 1}\n",
    "if config.weak_supervision:\n",
    "    input_queries, input_replies, query_lengths, reply_lengths, weak_distances = \\\n",
    "    trainer.infer_sess.run([trainer.infer_model.input_queries, \n",
    "                         trainer.infer_model.input_replies, \n",
    "                         trainer.infer_model.queries_lengths, \n",
    "                         trainer.infer_model.replies_lengths, \n",
    "                         trainer.infer_model.distances], \n",
    "                        feed_dict={trainer.infer_model.dropout_keep_prob: 1, \n",
    "                                   trainer.infer_model.add_echo: False})\n",
    "    feed_dict.update({model.input_queries: input_queries, \n",
    "                      model.input_replies: input_replies, \n",
    "                      model.query_lengths: query_lengths, \n",
    "                      model.reply_lengths: reply_lengths, \n",
    "                      model.weak_distances: weak_distances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_embedded, replies_embedded, queries_encoded, replies_encoded, queries_pooled, replies_pooled, \\\n",
    "queries_flattened, replies_flattened, logits, labels = sess.run([model.queries_embedded, model.replies_embedded, model.queries_encoded,\n",
    "                            model.replies_encoded,\n",
    "                            model.queries_pooled,\n",
    "                            model.replies_pooled,\n",
    "                            model.queries_flattened,\n",
    "                            model.replies_flattened,\n",
    "                           model.logits, \n",
    "                           model.labels\n",
    "                            ], feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 20, 1, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 20, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 20, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1, 1, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2555, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2555, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[847.7907  ],\n",
       "       [622.5545  ],\n",
       "       [396.15997 ],\n",
       "       ...,\n",
       "       [427.43973 ],\n",
       "       [-81.023415],\n",
       "       [380.96375 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x, derivative=False):\n",
    "    return x*(1-x) if derivative else 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angrypark/angryenv/lib/python3.5/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "predictions = sigmoid(logits)>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.225440313111546"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.equal(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angryenv",
   "language": "python",
   "name": "angryenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
